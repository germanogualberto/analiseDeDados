---
title: "AD2-Lab3-"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(dplyr)
library(ggplot2)
library(knitr)
library(caret)
library(rpart)
library(ada)
library(maxent)

```


```{r}
dadosTrain <- read_csv("data/train.csv")
dadosTest <- read_csv("data/test.csv")
dadosSample <- read_csv("data/sample_submission.csv")
View(dadosTest)
View(dadosTrain)
View(dadosSample)

```
1 Há desbalanceamento das classes (isto é, uma classe tem muito mais instâncias que outra)? Em que proporção? Quais efeitos colaterais o desbalanceamento de classes pode causar no classificador? Como você poderia tratar isso? (10 pt.)

```{r}
totalEleitos <- length(which(dadosTrain$situacao == "eleito"))
totalNaoEleitos <- length(which(dadosTrain$situacao == "nao_eleito"))
total <- totalEleitos + totalNaoEleitos

propEleitos = totalEleitos/total
propNaoEleitos = totalNaoEleitos/total

propEleitos
propNaoEleitos

proporcoes= c(propEleitos, propNaoEleitos)

barplot(proporcoes, main="Distribuição das Proporcoes",
        xlab="Classes",
        names.arg=c("Eleitos", "Não Eleitos"))
```
Há sim um desbalanciamento, sendo 13.4% de candidatos eleitos e 86.5% de candidatos não eleitos.

Grande parte dos algoritmos de classificação em Machine Learning são afetados por desbalanceamentos em classes preditoras. O principal efeito colateral causado por um desbalanceamento em um classificador é o seu enviesamento, tendo em vista que este irá inclinar-se a escolher a classe mais comum. 

Tratamento dos dados:

```{r}
c1 = cor(dadosTrain$total_despesa, dadosTrain$quantidade_despesas)
c2 = cor(dadosTrain$quantidade_despesas, dadosTrain$media_despesa)
c3 = cor(dadosTrain$quantidade_doacoes, dadosTrain$quantidade_doadores)
c4 = cor(dadosTrain$quantidade_despesas, dadosTrain$quantidade_fornecedores)
c5 = cor(dadosTrain$total_despesa, dadosTrain$total_receita)
c1
c2
c3
c4
c5
```
Como existe grande correlação entre algumas variáveis, o que pode levar a redudância, podemos desconsiderá-las no modelo.

```{r}
formula <- as.formula(situacao ~ uf + partido + quantidade_doacoes + total_despesa + sexo + grau )
```



2 Treine: um modelo de KNN, regressão logística, uma árvore de decisão e um modelo de adaboost. Tune esses modelos usando validação cruzada e controle overfitting se necessário, considerando as particularidades de cada modelo.  (20 pts.)

Modelo de KNN
```{r}

```


Regressão Logística
```{r}
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3, sampling = "up")
logitModel <- caret::train(formula, data=dadosTrain, method="glm", family="binomial",
                 trControl = ctrl, tuneLength = 10)
```
Arvore de decisão

```{r}
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 3, sampling = "up")
set.seed(3333)
decisionTreeModel <- train(formula, data=dadosTrain, method = "rpart",
                   parms = list(split = "information"),
                   trControl=ctrl,
                   tuneLength = 10)
```

Adaboost
```{r}
control <- rpart.control(cp = -1, maxdepth = 14, maxcompete = 1, xval = 0)
adaboostModel <- ada(formula, data = dadosTrain, type = c("discrete", "real", "gentle"), control = control, iter = 70)
```


3 Reporte precision, recall e f-measure no treino e validação. Há uma grande diferença de desempenho no treino/validação? Como você avalia os resultados? Justifique sua resposta. (10 pt.)

KNN
```{r}

```

Regressão Logistica
```{r}
pred = predict(logitModel, newdata=dadosTrain)
#confMatrix <- confusionMatrix(data=pred, dadosTrain$situacao)

#acc  <- confMatrix$overall['Accuracy']
#rec  <- recall(confMatrix$table, relevant = "eleito")
#pre  <- precision(confMatrix$table, relevant = "eleito")
#fmes <- F_meas(confMatrix$table, relevant = "eleito")
```

Arvore Decisão
```{r}
pred = predict(decisionTreeModel, newdata=dadosTrain)
#confMatrix <- confusionMatrix(data=pred, pred)

#acc  <- confMatrix$overall['Accuracy']
#rec  <- recall(confMatrix$table, relevant = "eleito")
#pre  <- precision(confMatrix$table, relevant = "eleito")
#fmes <- F_meas(confMatrix$table, relevant = "eleito")

#print (confMatrix)
```

Adaboost
```{r}

```




4Interprete as saídas dos modelos. Quais atributos parecem ser mais importantes de acordo com cada modelo? (20 pts.)

Modelo de KNN
```{r}

```

Regressão Logistica
```{r}
logitModel
#save.model(logitModel, "logitModel")
write.csv(c(logitModel$coefficients), file="result.csv") 


```

Arvore de Decisão
```{r}
decisionTreeModel
```

Adaboost
```{r}
adaboostModel
```

